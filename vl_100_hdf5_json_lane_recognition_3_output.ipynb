{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdhFmWDvXgH6",
        "outputId": "483b6d8f-a5b4-4f72-fce6-3f197d058144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.12 (default, Jan 15 2022, 18:48:18) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "r1pMHdEC9EjJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import glob\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from typing import Tuple, List, Dict, Iterable\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import logging\n",
        "import math\n",
        "from typing import Optional\n",
        "import random\n",
        "from pathlib import Path\n",
        "import h5py\n",
        "\n",
        "from typing import NamedTuple, Tuple, List\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install unrar"
      ],
      "metadata": {
        "id": "m45ggIE2EYKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "pdgYMK0cEYuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "yk7a4Vr5CNWP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htieeTB39JF_",
        "outputId": "d7384d9f-364b-4d98-880e-ce7141b068fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VMNUdLK39Kbl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unrar x -Y \"/content/drive/My Drive/Ilmenau/dataset.rar\" \"/tmp/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (1280, 960, 3)\n",
        "BATCH_SIZE = 32\n",
        "AMOUNT_OF_FRAMES = 500\n",
        "VALIDATION_SPLIT = 0.2\n",
        "MAX_LINES_PER_FRAME = 2\n",
        "MAX_NUM_POINTS =  91\n",
        "NUM_TYPE_OF_LINES = 4"
      ],
      "metadata": {
        "id": "sHlIU6PhB2WR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/tmp/dataset/VIL100/\"\n",
        "IMAGE_PATH = BASE_DIR + \"JPEGImages/\"\n",
        "JSON_PATH = BASE_DIR + \"Json/\"\n",
        "JSON_HDF5_DATASET_PATH = BASE_DIR + \"hdf5/\"\n",
        "\n",
        "print(IMAGE_PATH)\n",
        "print(JSON_PATH)\n",
        "print(JSON_HDF5_DATASET_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJCbS-7dDAav",
        "outputId": "6507bba9-83d8-47e0-f6f1-c0dc6aa94b99"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/dataset/VIL100/JPEGImages/\n",
            "/tmp/dataset/VIL100/Json/\n",
            "/tmp/dataset/VIL100/hdf5/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = glob.glob(IMAGE_PATH+'/*/*.jpg')\n",
        "json_files = glob.glob(JSON_PATH+'/*/*.json')\n",
        "json_glob_path = JSON_PATH + '/*/*.json'"
      ],
      "metadata": {
        "id": "OmOixe6VC9ih"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VIL100HDF5:\n",
        "    ROOT_FOLDER = 'hdf5'\n",
        "    GROUP_NAME = 'frame_polylines_labels'\n",
        "    POLYLINES_DATASET_NAME = 'polylines'\n",
        "    LABELS_DATASET_NAME = 'labels'\n",
        "LANE_ID_FULL_LIST = set(range(1, 3))\n",
        "\n",
        "\n",
        "class Vil100Json:\n",
        "    ANNOTATIONS = 'annotations'\n",
        "    ATTRIBUTE = 'attribute'\n",
        "    LANE = 'lane'\n",
        "    LANE_ID = 'lane_id'\n",
        "    POINTS = 'points'\n",
        "\n",
        "\n",
        "class VIL100Attribute:\n",
        "    \"\"\"Lane Attribute id (type lane) in jsons\"\"\"\n",
        "    SINGLE_WHITE_SOLID = 1\n",
        "    SINGLE_WHITE_DOTTED = 2\n",
        "    SINGLE_YELLOW_SOLID = 3\n",
        "    SINGLE_YELLOW_DOTTED = 4\n",
        "    DOUBLE_WHITE_SOLID = 5\n",
        "    DOUBLE_YELLOW_SOLID = 7\n",
        "    DOUBLE_YELLOW_DOTTED = 8\n",
        "    DOUBLE_WHITE_SOLID_DOTTED = 9\n",
        "    DOUBLE_WHITE_DOTTED_SOLID = 10\n",
        "    DOUBLE_SOLID_WHITE_AND_YELLOW = 13\n",
        "\n",
        "\n",
        "class LineType:\n",
        "    \"\"\"Type lane in our task\"\"\"\n",
        "    NO_LINE = 0\n",
        "    SINGLE_WHITE_SOLID = 1\n",
        "    SINGLE_WHITE_DOTTED = 2\n",
        "    DOUBLE_WHITE_SOLID = 3\n",
        "    ALL_LINES = {NO_LINE, SINGLE_WHITE_SOLID, SINGLE_WHITE_DOTTED, DOUBLE_WHITE_SOLID}\n",
        "\n",
        "\n",
        "VIL_100_colour_line = {\n",
        "    LineType.SINGLE_WHITE_SOLID: (255, 0, 0),  # single white solid\n",
        "    LineType.SINGLE_WHITE_DOTTED: (0, 255, 0),  # single white dotted\n",
        "    LineType.DOUBLE_WHITE_SOLID: (255, 125, 0),  # single yellow solid\n",
        "    # 4: (255, 255, 0),  # single yellow dotted\n",
        "    # 5: (255, 0, 0),  # double white solid\n",
        "    # 6: (255, 125, 0),  # double yellow solid\n",
        "    # 7: (255, 255, 0),  # double yellow dotted\n",
        "    # 8: (255, 0, 0),  # double white solid dotted\n",
        "    # 9: (255, 0, 0),  # double white dotted solid\n",
        "    # 10: (255, 0, 0),  # double solid white and yellow\n",
        "}\n",
        "\n",
        "\n",
        "def get_valid_attribute(attr: int) -> int:\n",
        "    \"\"\"Change attribute from VIL100 dataset to normal number without missings\"\"\"\n",
        "    _VIL_100_attributes = {\n",
        "        LineType.NO_LINE: LineType.NO_LINE,\n",
        "        VIL100Attribute.SINGLE_WHITE_SOLID: LineType.SINGLE_WHITE_SOLID,\n",
        "        VIL100Attribute.SINGLE_WHITE_DOTTED: LineType.SINGLE_WHITE_DOTTED,\n",
        "        VIL100Attribute.SINGLE_YELLOW_SOLID: LineType.SINGLE_WHITE_SOLID,\n",
        "        VIL100Attribute.SINGLE_YELLOW_DOTTED: LineType.SINGLE_WHITE_DOTTED,\n",
        "        VIL100Attribute.DOUBLE_WHITE_SOLID: LineType.DOUBLE_WHITE_SOLID,\n",
        "        VIL100Attribute.DOUBLE_YELLOW_SOLID: LineType.DOUBLE_WHITE_SOLID,\n",
        "        VIL100Attribute.DOUBLE_YELLOW_DOTTED: LineType.DOUBLE_WHITE_SOLID,\n",
        "        VIL100Attribute.DOUBLE_WHITE_SOLID_DOTTED: LineType.DOUBLE_WHITE_SOLID,\n",
        "        VIL100Attribute.DOUBLE_WHITE_DOTTED_SOLID: LineType.DOUBLE_WHITE_SOLID,\n",
        "        VIL100Attribute.DOUBLE_SOLID_WHITE_AND_YELLOW: LineType.DOUBLE_WHITE_SOLID,\n",
        "    }\n",
        "    return _VIL_100_attributes.get(attr, LineType.NO_LINE)\n",
        "\n",
        "\n",
        "def get_colour_from_one_hot_vector(vector: np.ndarray) -> Tuple[int, int, int]:\n",
        "    \"\"\"Get colour from one hot vector\"\"\"\n",
        "    return VIL_100_colour_line.get(int(np.argmax(vector, axis=1)), None)\n",
        "\n",
        "\n",
        "def one_hot_list_encoder(target_class_idx: int, num_classes: int) -> np.ndarray:\n",
        "    \"\"\"One-hot list encoder\"\"\"\n",
        "    target_vector = np.zeros(num_classes)\n",
        "    target_vector[target_class_idx] = 1\n",
        "    return target_vector"
      ],
      "metadata": {
        "id": "fyfgUKHeBmVa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VILLJsonConverter:\n",
        "\n",
        "    def __init__(self,\n",
        "                 max_lines_per_frame: int,\n",
        "                 max_num_points: int,\n",
        "                 num_type_of_lines: int,\n",
        "                 json_glob_path: str = None, ):\n",
        "\n",
        "        self.max_lines_per_frame = max_lines_per_frame\n",
        "        self.max_num_points = max_num_points\n",
        "        self.num_type_of_lines = num_type_of_lines\n",
        "        self.json_files = sorted(glob.glob(json_glob_path))\n",
        "        self.files_count = len(self.json_files)\n",
        "\n",
        "    def __get_polyline_with_label(self, lane: dict) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Get array from points list\"\"\"\n",
        "        points = np.array(\n",
        "            lane[Vil100Json.POINTS]).flatten()\n",
        "        points = np.pad(points, pad_width=(0, self.max_num_points * 2 - points.shape[0]))\n",
        "        # TODO @Karim: remember below `label.get(label)` is index 1,2,3,4\n",
        "        label = get_valid_attribute(lane.get(Vil100Json.ATTRIBUTE, LineType.NO_LINE))\n",
        "        labels = one_hot_list_encoder(label, self.num_type_of_lines)\n",
        "        return points, labels\n",
        "\n",
        "    def __get_polyline_and_label_from_file(self, json_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Retrieve from json file polylines and labels and format to nn input\n",
        "\n",
        "        :param json_path: json file path\n",
        "        :return: frame and tuple of labels\n",
        "        \"\"\"\n",
        "        with open(json_path) as f:\n",
        "            lanes: List[Dict[str, int]] = json.load(f)[Vil100Json.ANNOTATIONS][Vil100Json.LANE]\n",
        "            lanes = sorted(lanes, key=lambda lane: lane[Vil100Json.LANE_ID])\n",
        "\n",
        "            if lanes:\n",
        "                polylines, labels = np.array([]), np.array([])\n",
        "                # TODO @Karim: check another params in json files like \"occlusion\"\n",
        "                exist_lane = [x[Vil100Json.LANE_ID] for x in lanes]\n",
        "                missed_lane = LANE_ID_FULL_LIST - set(exist_lane)\n",
        "\n",
        "                for lane_id in range(1, self.max_lines_per_frame + 1):\n",
        "                    if lane_id in missed_lane:\n",
        "                        points = np.zeros(shape=(self.max_num_points * 2))\n",
        "                        label = one_hot_list_encoder(LineType.NO_LINE, self.num_type_of_lines)\n",
        "                    else:\n",
        "                        points, label = self.__get_polyline_with_label(lane=lanes[exist_lane.index(lane_id)])\n",
        "\n",
        "                    if lane_id % 2 == 0:\n",
        "                        polylines = np.append(polylines, points)\n",
        "                        labels = np.append(labels, label)\n",
        "                    else:\n",
        "                        polylines = np.insert(polylines, 0, points)\n",
        "                        labels = np.insert(labels, 0, label)\n",
        "\n",
        "                return polylines, labels\n",
        "            else:\n",
        "                empty_label = one_hot_list_encoder(LineType.NO_LINE, self.num_type_of_lines)\n",
        "                polylines_empty_shape = self.max_lines_per_frame * self.max_num_points * 2\n",
        "                return np.zeros(shape=polylines_empty_shape), np.array(\n",
        "                    [empty_label for x in range(self.max_lines_per_frame)]).flatten()\n",
        "\n",
        "    def exec(self) -> None:\n",
        "        \"\"\"Convert and save json files to new hdf5 files\"\"\"\n",
        "        for json_file_path in self.json_files:\n",
        "            polylines, labels = self.__get_polyline_and_label_from_file(json_file_path)\n",
        "\n",
        "            full_path_list = json_file_path.split('/')\n",
        "            full_path_list[-3] = VIL100HDF5.ROOT_FOLDER\n",
        "            root_path = full_path_list[:-1]\n",
        "            frame_name = full_path_list[-1]\n",
        "\n",
        "            Path(f\"{'/'.join(root_path)}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            with h5py.File(f\"{'/'.join(root_path)}/{frame_name}.hdf5\", \"w\") as f:\n",
        "                grp = f.create_group(VIL100HDF5.GROUP_NAME)\n",
        "                grp.create_dataset(VIL100HDF5.POLYLINES_DATASET_NAME, data=polylines, dtype='int32')\n",
        "                grp.create_dataset(VIL100HDF5.LABELS_DATASET_NAME, data=labels, dtype='int32')\n"
      ],
      "metadata": {
        "id": "fbWFrqSmBpu0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = VILLJsonConverter(\n",
        "        max_lines_per_frame=MAX_LINES_PER_FRAME,\n",
        "        max_num_points=MAX_NUM_POINTS,\n",
        "        num_type_of_lines=NUM_TYPE_OF_LINES,\n",
        "        json_glob_path=json_glob_path,\n",
        "    )"
      ],
      "metadata": {
        "id": "r40mnshXByAO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter.exec()"
      ],
      "metadata": {
        "id": "Y9clI0smB6C6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ejnvAiA5T1Yv"
      },
      "outputs": [],
      "source": [
        "def calculate_perspective_transform_matrix(width: int, height: int, reverse_flag=False) -> Tuple[\n",
        "    np.ndarray]:\n",
        "    \"\"\"\n",
        "    Calculate transformation matrix for perspective transformation\n",
        "    :param width: frame width\n",
        "    :param height: frame height\n",
        "    :param reverse_flag: create reverse matrix for reverting to initial frame\n",
        "    :return: matrix for transformation the frame\n",
        "    \"\"\"\n",
        "    # TODO @Karim: check on real Audi Q2 input frame\n",
        "    high_left_crd, high_right_crd = (550, 530), (700, 530)\n",
        "    down_left_crd, down_right_crd, = (0, height - 150), (width, height - 150)\n",
        "\n",
        "    initial_matrix = np.float32([[high_left_crd, high_right_crd,\n",
        "                                  down_left_crd, down_right_crd]])\n",
        "    final_matrix = np.float32([[(0, 0), (width, 0), (0, height), (width, height)]])\n",
        "\n",
        "    return cv2.getPerspectiveTransform(initial_matrix, final_matrix) \\\n",
        "        if not reverse_flag else cv2.getPerspectiveTransform(final_matrix, initial_matrix)\n",
        "\n",
        "\n",
        "def transform_frame(frame: np.ndarray, width: int, height: int, reverse_flag=False) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Perform perspective transformation\n",
        "    :param frame: frame\n",
        "    :param width: frame width\n",
        "    :param height: frame height\n",
        "    :param reverse_flag: cancel perspective transformation\n",
        "    :return: changed (un)transformed frame\n",
        "    \"\"\"\n",
        "    if not reverse_flag:\n",
        "        initial_matrix = calculate_perspective_transform_matrix(width, height)\n",
        "        frame = cv2.warpPerspective(frame, initial_matrix, dsize=(width, height))\n",
        "    else:\n",
        "        final_matrix = calculate_perspective_transform_matrix(width, height, reverse_flag=True)\n",
        "        frame = cv2.warpPerspective(frame, final_matrix, dsize=(width, height))\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fjYjpIH8Yv6A"
      },
      "outputs": [],
      "source": [
        "class SimpleFrameGenerator(Sequence):\n",
        "    \"\"\"Sequence of frames generator\n",
        "\n",
        "    Usage for training NN that could process independent\n",
        "    frames without context window etc\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_type_of_lines=4,\n",
        "                 max_num_points=91,\n",
        "                 max_lines_per_frame=2,\n",
        "                 rescale=1 / 255.,  # TODO @Karim: include and use later\n",
        "                 batch_size: int = 8,\n",
        "                 target_shape: Tuple[int, int] = (1280, 960),\n",
        "                 shuffle: bool = False,\n",
        "                 nb_channel: int = 3,  # TODO: Use rgb later\n",
        "                 files: Optional[List[str]] = None,\n",
        "                 json_files: Optional[List[str]] = None):\n",
        "        \"\"\"\n",
        "        :param subset: training or validation data\n",
        "        :param max_lines_per_frame: maxinum number of lines per frame\n",
        "        :param max_num_points: maximum number of points un one polyline\n",
        "        :param num_type_of_lines: number of possible lines on road\n",
        "        :param rescale:\n",
        "        :param batch_size: batch size of the dataset\n",
        "        :param target_shape: final size for NN input\n",
        "        :param shuffle: shuffle flag of frames sequences\n",
        "        :param split: split dataset to train/test\n",
        "        :param nb_channel: grayscaled or RGB frames\n",
        "        :param frame_glob_path: glob pattern of frames\n",
        "        :param json_glob_path: glob pattern path of jsons\n",
        "        \"\"\"\n",
        "        self.max_lines_per_frame = max_lines_per_frame\n",
        "        self.max_num_points = max_num_points\n",
        "        self.num_type_of_lines = num_type_of_lines\n",
        "        self.rescale = rescale\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.target_shape = target_shape\n",
        "        self.nb_channel = nb_channel\n",
        "        self.files = files\n",
        "        self.json_files = json_files\n",
        "        self.files_count = len(self.files)\n",
        "\n",
        "        if shuffle:\n",
        "            temp = list(zip(self.files, self.json_files))\n",
        "            random.shuffle(temp)\n",
        "            self.files, self.json_files = zip(*temp)\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(self.files_count / self.batch_size)\n",
        "\n",
        "    def __get_polyline_and_label_from_file(self, json_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Get from hdf5 all polylines and their labels\n",
        "        :param json_path: path of json file\n",
        "        :return: polylines with labels\n",
        "        \"\"\"\n",
        "        file = h5py.File(json_path, 'r')\n",
        "        group = file.get(VIL100HDF5.GROUP_NAME)\n",
        "        return group.get(VIL100HDF5.POLYLINES_DATASET_NAME), group.get(VIL100HDF5.LABELS_DATASET_NAME)\n",
        "\n",
        "    def __getitem__(self, idx) -> Tuple[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
        "        batch_frames_path = self.files[idx * self.batch_size:\n",
        "                                       (idx + 1) * self.batch_size]\n",
        "        batch_json_path = self.json_files[idx * self.batch_size:\n",
        "                                          (idx + 1) * self.batch_size]\n",
        "\n",
        "        polylines_list, labels_list = self.__get_polyline_and_label_from_file(batch_json_path[0])\n",
        "        for _json in batch_json_path[1:]:\n",
        "            polylines, labels = self.__get_polyline_and_label_from_file(_json)\n",
        "            polylines_list = np.vstack((polylines_list, polylines))\n",
        "            labels_list = np.vstack((labels_list, labels))\n",
        "\n",
        "        return np.array([\n",
        "            resize(imread(file_name) * self.rescale, self.target_shape) for file_name in\n",
        "            batch_frames_path]), (polylines_list,) + tuple(np.hsplit(labels_list, self.max_lines_per_frame))\n",
        "\n",
        "\n",
        "class SimpleFrameDataGen:\n",
        "    TRAINING = 'training'\n",
        "    VALIDATION = 'validation'\n",
        "\n",
        "    __reverse_dataset_type = {\n",
        "        TRAINING: VALIDATION,\n",
        "        VALIDATION: TRAINING\n",
        "    }\n",
        "    __dataset = {}\n",
        "\n",
        "    def __init__(self,\n",
        "                 rescale=1 / 255.,\n",
        "                 validation_split: Optional[float] = None,\n",
        "                 frame_glob_path: str = \"\",\n",
        "                 json_hdf5_glob_path: str = \"\"):\n",
        "        \"\"\"\n",
        "        :param validation_split: split for train/validation sets\n",
        "        :param rescale:\n",
        "        :param frame_glob_path: glob pattern of frames\n",
        "        :param json_glob_path: glob pattern path of jsons\n",
        "        \"\"\"\n",
        "        self.rescale = rescale\n",
        "        self.validation_split = validation_split\n",
        "\n",
        "        self.__frame_glob_path = frame_glob_path\n",
        "        self.__json_hdf5_glob_path = json_hdf5_glob_path\n",
        "\n",
        "    def flow_from_directory(self, subset: str = TRAINING,\n",
        "                            shuffle: bool = True, number_files: int = 2000, *args, **kwargs) -> SimpleFrameGenerator:\n",
        "        \"\"\"\n",
        "        Get generator for subset\n",
        "        :param subset: 'training' or 'validation'\n",
        "        :param shuffle: flag for shuffling\n",
        "        :param number_files: rectrict max number of files from dataset\n",
        "        :param args: args for specific dataset\n",
        "        :param kwargs: kwargs for specific dataset\n",
        "        :return: Specific generator for specific subset\n",
        "        \"\"\"\n",
        "\n",
        "        files = sorted(glob.glob(self.__frame_glob_path))\n",
        "        log.info(f\"Number of files in dataset: {len(files)}. Using in training/validation: {number_files}\")\n",
        "        files = files[:number_files]\n",
        "\n",
        "        json_files = sorted(glob.glob(self.__json_hdf5_glob_path))[:number_files]\n",
        "        files_count = len(files)\n",
        "        json_files_count = len(json_files)\n",
        "\n",
        "        if files_count != json_files_count:\n",
        "            log.error(f\"Dataset files error\"\n",
        "                      f\"Number of frames: ({files_count}). \"\n",
        "                      f\"Number of jsons({json_files_count}\")\n",
        "            raise FileNotFoundError(\n",
        "                f\"Numbers of frames and jsons are not equal!\")\n",
        "\n",
        "        if not self.__reverse_dataset_type.get(subset):\n",
        "            log.error(f'Wrong subset value: \"{subset}\"')\n",
        "            raise ValueError(f'Wrong type of subset - {subset}. '\n",
        "                             f'Available types: {self.__reverse_dataset_type.keys()}')\n",
        "\n",
        "        if self.validation_split and 0.0 < self.validation_split < 1.0:\n",
        "            split = int(files_count * (1 - self.validation_split))\n",
        "            if subset == self.TRAINING:\n",
        "                files = files[:split]\n",
        "                json_files = json_files[:split]\n",
        "            else:\n",
        "                files = files[split:]\n",
        "                json_files = json_files[split:]\n",
        "\n",
        "        return SimpleFrameGenerator(rescale=self.rescale,\n",
        "                                    files=files,\n",
        "                                    shuffle=shuffle,\n",
        "                                    json_files=json_files,\n",
        "                                    *args, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "eazCkLeoNyFK"
      },
      "outputs": [],
      "source": [
        "data_gen = SimpleFrameDataGen(\n",
        "    validation_split=VALIDATION_SPLIT, \n",
        "    frame_glob_path=IMAGE_PATH+'/*/*.jpg', \n",
        "    json_hdf5_glob_path=JSON_HDF5_DATASET_PATH+'/*/*.hdf5',\n",
        ")\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "  subset='training', shuffle=True, batch_size = BATCH_SIZE, \n",
        "  number_files=AMOUNT_OF_FRAMES, max_lines_per_frame=MAX_LINES_PER_FRAME,\n",
        "  max_num_points = MAX_NUM_POINTS, num_type_of_lines = NUM_TYPE_OF_LINES\n",
        ")\n",
        "\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "  subset='validation', shuffle=True, batch_size = BATCH_SIZE, \n",
        "  number_files=AMOUNT_OF_FRAMES, max_lines_per_frame=MAX_LINES_PER_FRAME,\n",
        "  max_num_points = MAX_NUM_POINTS, num_type_of_lines = NUM_TYPE_OF_LINES\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqKywRZMrMCr"
      },
      "outputs": [],
      "source": [
        "# for image_polylines in validation_generator:\n",
        "#     print(image_polylines[0].shape)\n",
        "#     print(image_polylines[1][0].shape)\n",
        "#     print(image_polylines[1][1].shape)\n",
        "#     break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4zVvmiEN9R_M"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "model_name = 'lane_line_cnn_model'\n",
        "\n",
        "def build_model(polyline_output_shape:int ,label_output_shape:int, input_shape=(1280, 960, 3)):\n",
        "\n",
        "    # pretrained\n",
        "    pre_trained_model = tf.keras.applications.InceptionResNetV2(input_shape=input_shape,\n",
        "                            weights='imagenet',\n",
        "                            include_top=False)  \n",
        "    global_max_pool = layers.GlobalMaxPool2D()(pre_trained_model.output)\n",
        "    dropout_max_pool = layers.Dropout(.2)(global_max_pool)\n",
        "    \n",
        "    # polyline part\n",
        "    dense_polyline = tf.keras.layers.Dense(units=512, activation='relu')(dropout_max_pool)\n",
        "    dropout_polyine = layers.Dropout(.2)(dense_polyline)\n",
        "    dense_polyline_2 = tf.keras.layers.Dense(units=512, activation='relu')(dropout_polyine)\n",
        "    dropout_polyine_2 = layers.Dropout(.2)(dense_polyline_2)\n",
        "\n",
        "    # label common part\n",
        "    dense_label = tf.keras.layers.Dense(units=256, activation='relu')(dropout_max_pool)\n",
        "    dropout_label = layers.Dropout(.2)(dense_label)\n",
        "\n",
        "    # lane 1 part\n",
        "    x = tf.keras.layers.Dense(units=128, activation='relu')(dropout_label)\n",
        "    x = layers.Dropout(.2)(x)\n",
        "    x = tf.keras.layers.Dense(units=64, activation='relu')(x)\n",
        "    x = layers.Dropout(.2)(x)\n",
        "    x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
        "    x = layers.Dropout(.2)(x)\n",
        "   \n",
        "    # lane 2 part\n",
        "    y = tf.keras.layers.Dense(units=128, activation='relu')(dropout_label)\n",
        "    y = layers.Dropout(.2)(y)\n",
        "    y = tf.keras.layers.Dense(units=64, activation='relu')(y)\n",
        "    y = layers.Dropout(.2)(y)\n",
        "    y = tf.keras.layers.Dense(units=32, activation='relu')(y)\n",
        "    y = layers.Dropout(.2)(y)\n",
        "\n",
        "    # output\n",
        "    polyline_output = layers.Dense(polyline_output_shape,name='polyline_output')(dropout_polyine_2)\n",
        "    label_output_1 = layers.Dense(label_output_shape, activation='softmax', name='label_output_1')(x)\n",
        "    label_output_2 = layers.Dense(label_output_shape, activation='softmax', name='label_output_2')(y)\n",
        "\n",
        "    model = Model(pre_trained_model.input, outputs=[\n",
        "        polyline_output,\n",
        "        label_output_1,\n",
        "        label_output_2,\n",
        "      ], name = model_name\n",
        "    )\n",
        "\n",
        "    return model, pre_trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "E86MF8po1u_p"
      },
      "outputs": [],
      "source": [
        "logdir = f\"logs/{model_name}\"\n",
        "checkpoint_filepath = f\"/model/{model_name}\"\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "early_stop_polyline_callback = tf.keras.callbacks.EarlyStopping(patience=6, monitor='val_polyline_output_loss')\n",
        "\n",
        "reduce_lr_callback_depends_on_polyline_loss = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_polyline_output_loss', factor=0.7, patience=2, verbose=1, mode='auto',\n",
        "    min_delta=0.0001, cooldown=0, min_lr=0.00001\n",
        ")\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_polyline_output_loss',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dCnz_gehb-JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be36fbcd-bd65-41c5-c442-137135e4e942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 6s 0us/step\n",
            "219070464/219055592 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model, pre_trained_model = build_model(\n",
        "    polyline_output_shape=MAX_NUM_POINTS * 2 * MAX_LINES_PER_FRAME, \n",
        "    label_output_shape=NUM_TYPE_OF_LINES, \n",
        "    input_shape = INPUT_SHAPE)\n",
        "# print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1t-RucGn0E4P"
      },
      "outputs": [],
      "source": [
        "pre_trained_model.trainable = False\n",
        "# print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JjwwwR25pM5X"
      },
      "outputs": [],
      "source": [
        "# tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
        "# tf.keras.utils.plot_model(model, \"multi_output_model.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1ASFtrskei1b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "model.compile(loss= {\n",
        "      'polyline_output':tf.keras.losses.MeanSquaredLogarithmicError(),\n",
        "      'label_output_1':tf.keras.losses.CategoricalCrossentropy(),\n",
        "      'label_output_2':tf.keras.losses.CategoricalCrossentropy(),\n",
        "    },\n",
        "    optimizer=Adam(learning_rate=learning_rate),\n",
        "    metrics={'polyline_output':tf.keras.metrics.MeanSquaredLogarithmicError(),\n",
        "             'label_output_1':'accuracy',\n",
        "             'label_output_2':'accuracy',\n",
        "             },\n",
        "    loss_weights={\n",
        "        \"polyline_output\": 500, \n",
        "        \"label_output_1\": 0.1,\n",
        "        \"label_output_2\": 0.1,\n",
        "      },)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "fRNqOCizesay",
        "outputId": "d7c75541-ce2e-48b0-bdcb-fea24113f794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "13/13 - 220s - loss: 2089.3145 - polyline_output_loss: 4.1785 - label_output_1_loss: 0.0956 - label_output_2_loss: 0.7441 - polyline_output_mean_squared_logarithmic_error: 4.1785 - label_output_1_accuracy: 0.9650 - label_output_2_accuracy: 0.8275 - val_loss: 1490.0229 - val_polyline_output_loss: 2.9728 - val_label_output_1_loss: 36.1039 - val_label_output_2_loss: 0.0000e+00 - val_polyline_output_mean_squared_logarithmic_error: 2.9728 - val_label_output_1_accuracy: 0.0000e+00 - val_label_output_2_accuracy: 1.0000 - lr: 0.0010 - 220s/epoch - 17s/step\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-5b7cc506a310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mearly_stop_polyline_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mreduce_lr_callback_depends_on_polyline_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                         \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                       ],\n\u001b[1;32m     11\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=20,\n",
        "                    verbose=2,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=[\n",
        "                        tensorboard_callback,\n",
        "                        early_stop_polyline_callback,\n",
        "                        reduce_lr_callback_depends_on_polyline_loss,\n",
        "                        model_checkpoint_callback,\n",
        "                      ],\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXNNF1iL2nJB"
      },
      "outputs": [],
      "source": [
        "# loss, polyline_output_loss,label_output_loss, polyline_output_mean_squared_logarithmic_error, label_output_accuracy = model.evaluate(validation_generator)\n",
        "# print(f\" \\\n",
        "#   Loss:{loss}\\n \\\n",
        "#   polyline_output_loss:{polyline_output_loss}\\n \\\n",
        "#   label_output_loss:{label_output_loss}\\n \\\n",
        "#   polyline_output_mean_squared_logarithmic_error:{polyline_output_mean_squared_logarithmic_error}\\n \\\n",
        "#   label_output_accuracy:{label_output_accuracy}\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKYNrqGcwiZv"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idAb55Mi2IWJ"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p saved_model\n",
        "# model.save('saved_model/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4JC9Mr24hF5"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWVYqvsp6ZMC"
      },
      "outputs": [],
      "source": [
        "# files.download(\"saved_model/my_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX33CM7f0g4O"
      },
      "outputs": [],
      "source": [
        "model_weight_name = f'{model_name}-weights.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15WhaJLJ6pSc"
      },
      "outputs": [],
      "source": [
        "# model.save(model_name) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxGvffvO7ELT"
      },
      "outputs": [],
      "source": [
        "# files.download(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2Jgjaci-sET"
      },
      "outputs": [],
      "source": [
        "model.save_weights(model_weight_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "o6rjRhAf-zVp",
        "outputId": "9c7981a2-7cbc-4f88-e822-fe3735992ebb"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_f2ac3c13-656d-47b5-affb-608b65b192e9\", \"lane-line-recognition-model.h5-weights.h5\", 225990144)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(model_weight_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP_WCXLf-3oc"
      },
      "outputs": [],
      "source": [
        "res = model.predict(validation_generator[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ75TNcXFkBX"
      },
      "outputs": [],
      "source": [
        "# res[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcFCDmsmYTLY",
        "outputId": "7f5ed47a-ba60-46a6-81ca-0e9a7f6877b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.6892014e-03, 7.5523233e-01, 2.4188313e-01, 1.9534070e-04],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res[1][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6b9JZCYYpvB",
        "outputId": "92f08515-cc24-4e8b-97ea-e57188fd8716"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00170986, 0.48654553, 0.5039854 , 0.0077592 ], dtype=float32)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res[2][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiIIWkkOFoxC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "vl_100_binary_lane_recognition_3_output.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}